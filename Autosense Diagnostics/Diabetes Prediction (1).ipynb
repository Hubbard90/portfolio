{"cells":[{"cell_type":"code","execution_count":2,"id":"502b1a2f","metadata":{"id":"502b1a2f","executionInfo":{"status":"ok","timestamp":1765203169958,"user_tz":-660,"elapsed":6792,"user":{"displayName":"Julio Lim","userId":"08767434591465252695"}}},"outputs":[],"source":["!pip -q install xgboost lightgbm imbalanced-learn\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, classification_report, confusion_matrix\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.calibration import CalibratedClassifierCV\n","\n","from sklearn.linear_model import LogisticRegression\n","from imblearn.ensemble import BalancedRandomForestClassifier\n","import xgboost as xgb\n","import lightgbm as lgb\n","\n","RANDOM_STATE = 0\n","np.random.seed(RANDOM_STATE)\n"]},{"cell_type":"code","execution_count":3,"id":"64cccf91","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"64cccf91","executionInfo":{"status":"ok","timestamp":1765203170892,"user_tz":-660,"elapsed":929,"user":{"displayName":"Julio Lim","userId":"08767434591465252695"}},"outputId":"b6061751-20a1-434d-dae5-d04c002e7282"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (170000, 23)\n","Test shape: (30000, 22)\n","\n","Train columns: ['ID', 'Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n","\n","Test columns: ['ID', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n"]}],"source":["\n","# Import Data\n","\n","TRAIN_PATH = \"data_train.csv\"\n","TEST_PATH = \"data_test.csv\"\n","TARGET_COL = \"Diabetes_binary\"\n","\n","df_train = pd.read_csv(TRAIN_PATH)\n","df_test = pd.read_csv(TEST_PATH)\n","\n","print(\"Train shape:\", df_train.shape)\n","print(\"Test shape:\", df_test.shape)\n","print(\"\\nTrain columns:\", df_train.columns.tolist())\n","print(\"\\nTest columns:\", df_test.columns.tolist())"]},{"cell_type":"code","execution_count":4,"id":"a26e4d8a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a26e4d8a","executionInfo":{"status":"ok","timestamp":1765203171083,"user_tz":-660,"elapsed":189,"user":{"displayName":"Julio Lim","userId":"08767434591465252695"}},"outputId":"721987e5-b72c-47ed-c7a3-0c441c77c71b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape after feature engineering: (170000, 29)\n","Test shape after feature engineering: (30000, 28)\n"]}],"source":["\n","# Feature Engineering\n","\n","def add_engineered_features(df: pd.DataFrame) -> pd.DataFrame:\n","    df = df.copy()\n","\n","    # BMI / Age ratio (only if both exist and Age > 0)\n","    if \"BMI\" in df.columns and \"Age\" in df.columns:\n","        df[\"BMI_Age\"] = df[\"BMI\"] / (df[\"Age\"].replace(0, np.nan))\n","        df[\"BMI_Age\"] = df[\"BMI_Age\"].fillna(df[\"BMI_Age\"].median())\n","\n","    # Physically unhealthy days > 10\n","    if \"PhysHlth\" in df.columns:\n","        df[\"Physically_Unhealthy\"] = (df[\"PhysHlth\"] > 10).astype(int)\n","\n","    # Mentally unhealthy days > 10\n","    if \"MentHlth\" in df.columns:\n","        df[\"Mentally_Unhealthy\"] = (df[\"MentHlth\"] > 10).astype(int)\n","\n","    # Obesity flag\n","    if \"BMI\" in df.columns:\n","        df[\"Obese\"] = (df[\"BMI\"] >= 30).astype(int)\n","\n","    if \"Age\" in df.columns:\n","        df[\"Old\"] = (df[\"Age\"] >= 9).astype(int)\n","\n","    # High-risk combo: HighBP + HighChol + Smoker\n","    if all(c in df.columns for c in [\"HighBP\", \"HighChol\", \"Smoker\"]):\n","        def to_binary(col):\n","            if df[col].dtype == \"O\":\n","                return df[col].map({\"Yes\": 1, \"No\": 0}).fillna(0).astype(int)\n","            else:\n","                return df[col].astype(float).fillna(0).astype(int)\n","\n","        hb = to_binary(\"HighBP\")\n","        hc = to_binary(\"HighChol\")\n","        sm = to_binary(\"Smoker\")\n","        df[\"HighRiskCombo\"] = ((hb == 1) & (hc == 1) & (sm == 1)).astype(int)\n","\n","    return df\n","\n","df_train = add_engineered_features(df_train)\n","df_test = add_engineered_features(df_test)\n","\n","print(\"Train shape after feature engineering:\", df_train.shape)\n","print(\"Test shape after feature engineering:\", df_test.shape)\n"]},{"cell_type":"code","execution_count":5,"id":"8780bea9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8780bea9","executionInfo":{"status":"ok","timestamp":1765203171213,"user_tz":-660,"elapsed":128,"user":{"displayName":"Julio Lim","userId":"08767434591465252695"}},"outputId":"2597970d-922f-4cb3-d41d-e32523fc4586"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using 'ID' as ID column for submission.\n","\n","Number of feature columns: 27\n"]}],"source":["\n","y = df_train[TARGET_COL].astype(int)\n","X = df_train.drop(columns=[TARGET_COL]).copy()\n","\n","candidate_id_cols = [c for c in df_test.columns\n","                     if c.lower().startswith(\"id\") or c.lower().endswith(\"id\")]\n","\n","if candidate_id_cols:\n","    ID_COL = candidate_id_cols[0]\n","    print(f\"Using '{ID_COL}' as ID column for submission.\")\n","    test_ids = df_test[ID_COL].copy()\n","    X_test = df_test.drop(columns=[ID_COL]).copy()\n","else:\n","    print(\"No explicit ID column found. Using row index as ID.\")\n","    ID_COL = \"ID\"\n","    test_ids = pd.Series(np.arange(1, len(df_test) + 1), name=ID_COL)\n","    X_test = df_test.copy()\n","\n","common_cols = [c for c in X.columns if c in X_test.columns]\n","X = X[common_cols].copy()\n","X_test = X_test[common_cols].copy()\n","\n","print(\"\\nNumber of feature columns:\", len(common_cols))\n"]},{"cell_type":"code","execution_count":6,"id":"be7eca91","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"be7eca91","executionInfo":{"status":"ok","timestamp":1765203171492,"user_tz":-660,"elapsed":277,"user":{"displayName":"Julio Lim","userId":"08767434591465252695"}},"outputId":"edddc600-2a04-404f-9cf8-7c8555627889"},"outputs":[{"output_type":"stream","name":"stdout","text":["X_train: (136000, 27) X_val: (34000, 27)\n"]}],"source":["\n","# Split\n","\n","X_train, X_val, y_train, y_val = train_test_split(\n","    X, y,\n","    test_size=0.2,\n","    stratify=y,\n","    random_state=RANDOM_STATE\n",")\n","\n","print(\"X_train:\", X_train.shape, \"X_val:\", X_val.shape)\n"]},{"cell_type":"code","execution_count":7,"id":"9cace4e0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cace4e0","executionInfo":{"status":"ok","timestamp":1765203171499,"user_tz":-660,"elapsed":5,"user":{"displayName":"Julio Lim","userId":"08767434591465252695"}},"outputId":"8b1c9599-8cb4-4b95-a210-2868bd36d98c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Numeric features: 14\n","Categorical features: 13\n"]}],"source":["# Identify numeric and categorical columns\n","numeric_features = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n","categorical_features = X_train.select_dtypes(include=[\"object\", \"bool\", \"category\"]).columns.tolist()\n","\n","print(\"Numeric features:\", len(numeric_features))\n","print(\"Categorical features:\", len(categorical_features))\n","\n","numeric_transformer = Pipeline(steps=[\n","    (\"imputer\", SimpleImputer(strategy=\"median\"))\n","])\n","\n","categorical_transformer = Pipeline(steps=[\n","    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n","    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n","])\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        (\"num\", numeric_transformer, numeric_features),\n","        (\"cat\", categorical_transformer, categorical_features)\n","    ]\n",")\n"]},{"cell_type":"code","execution_count":8,"id":"e573c856","metadata":{"id":"e573c856","executionInfo":{"status":"ok","timestamp":1765203171518,"user_tz":-660,"elapsed":17,"user":{"displayName":"Julio Lim","userId":"08767434591465252695"}}},"outputs":[],"source":["\n","# Threshold Tuning\n","\n","def tune_threshold_for_f1(y_true, y_proba, positive_label=1):\n","    \"\"\"Brute-force search over thresholds to maximize F1 for the positive class.\"\"\"\n","    best_threshold = 0.5\n","    best_f1 = -1\n","\n","    for thr in np.linspace(0.2, 0.8, 61):  # step = 0.01\n","        y_pred = (y_proba >= thr).astype(int)\n","        f1 = f1_score(y_true, y_pred, pos_label=positive_label)\n","        if f1 > best_f1:\n","            best_f1 = f1\n","            best_threshold = thr\n","\n","    return best_threshold, best_f1\n","\n","def evaluate_model(name, model, X_tr, y_tr, X_val, y_val):\n","    print(f\"\\n=============================\")\n","    print(f\"Training model: {name}\")\n","    print(f\"=============================\")\n","    model.fit(X_tr, y_tr)\n","\n","    # Predicted probabilities for positive class\n","    y_val_proba = model.predict_proba(X_val)[:, 1]\n","    best_thr, best_f1 = tune_threshold_for_f1(y_val, y_val_proba, positive_label=1)\n","\n","    y_val_pred = (y_val_proba >= best_thr).astype(int)\n","\n","    print(f\"Best threshold for F1(class 1): {best_thr:.4f}\")\n","    print(f\"Best F1(class 1) on validation: {best_f1:.4f}\")\n","    print(\"\\nConfusion Matrix (val):\")\n","    print(confusion_matrix(y_val, y_val_pred, labels=[0, 1]))\n","    print(\"\\nClassification Report (val):\")\n","    print(classification_report(y_val, y_val_pred, zero_division=0))\n","\n","    return {\n","        \"name\": name,\n","        \"model\": model,\n","        \"threshold\": best_thr,\n","        \"f1_class1\": best_f1\n","    }\n"]},{"cell_type":"code","execution_count":9,"id":"c6e3d637","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c6e3d637","executionInfo":{"status":"ok","timestamp":1765203282696,"user_tz":-660,"elapsed":111164,"user":{"displayName":"Julio Lim","userId":"08767434591465252695"}},"outputId":"f282f746-bad4-4c36-d76f-3cca55b689dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=============================\n","Training model: XGBoost_unweighted\n","=============================\n","Best threshold for F1(class 1): 0.2500\n","Best F1(class 1) on validation: 0.5134\n","\n","Confusion Matrix (val):\n","[[22406  5571]\n"," [ 2019  4004]]\n","\n","Classification Report (val):\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.80      0.86     27977\n","           1       0.42      0.66      0.51      6023\n","\n","    accuracy                           0.78     34000\n","   macro avg       0.67      0.73      0.68     34000\n","weighted avg       0.83      0.78      0.79     34000\n","\n","\n","scale_pos_weight (train) = 4.6448\n","\n","=============================\n","Training model: XGBoost_weighted\n","=============================\n","Best threshold for F1(class 1): 0.5900\n","Best F1(class 1) on validation: 0.5087\n","\n","Confusion Matrix (val):\n","[[22611  5366]\n"," [ 2138  3885]]\n","\n","Classification Report (val):\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.81      0.86     27977\n","           1       0.42      0.65      0.51      6023\n","\n","    accuracy                           0.78     34000\n","   macro avg       0.67      0.73      0.68     34000\n","weighted avg       0.83      0.78      0.80     34000\n","\n","\n","=============================\n","Training model: XGBoost_weighted_calibrated\n","=============================\n","Best threshold for F1(class 1): 0.2500\n","Best F1(class 1) on validation: 0.4882\n","\n","Confusion Matrix (val):\n","[[22466  5511]\n"," [ 2298  3725]]\n","\n","Classification Report (val):\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.80      0.85     27977\n","           1       0.40      0.62      0.49      6023\n","\n","    accuracy                           0.77     34000\n","   macro avg       0.66      0.71      0.67     34000\n","weighted avg       0.82      0.77      0.79     34000\n","\n","\n","=============================\n","Training model: BalancedRandomForest\n","=============================\n","Best threshold for F1(class 1): 0.6100\n","Best F1(class 1) on validation: 0.5124\n","\n","Confusion Matrix (val):\n","[[23007  4970]\n"," [ 2236  3787]]\n","\n","Classification Report (val):\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.82      0.86     27977\n","           1       0.43      0.63      0.51      6023\n","\n","    accuracy                           0.79     34000\n","   macro avg       0.67      0.73      0.69     34000\n","weighted avg       0.83      0.79      0.80     34000\n","\n","\n","=============================\n","Training model: LightGBM_balanced\n","=============================\n","[LightGBM] [Info] Number of positive: 24093, number of negative: 111907\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038315 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 488\n","[LightGBM] [Info] Number of data points in the train set: 136000, number of used features: 40\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Best threshold for F1(class 1): 0.6300\n","Best F1(class 1) on validation: 0.5169\n","\n","Confusion Matrix (val):\n","[[23034  4943]\n"," [ 2201  3822]]\n","\n","Classification Report (val):\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.82      0.87     27977\n","           1       0.44      0.63      0.52      6023\n","\n","    accuracy                           0.79     34000\n","   macro avg       0.67      0.73      0.69     34000\n","weighted avg       0.83      0.79      0.80     34000\n","\n","\n","=============================\n","Training model: LogisticRegression\n","=============================\n","Best threshold for F1(class 1): 0.2400\n","Best F1(class 1) on validation: 0.5138\n","\n","Confusion Matrix (val):\n","[[22518  5459]\n"," [ 2054  3969]]\n","\n","Classification Report (val):\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.80      0.86     27977\n","           1       0.42      0.66      0.51      6023\n","\n","    accuracy                           0.78     34000\n","   macro avg       0.67      0.73      0.69     34000\n","weighted avg       0.83      0.78      0.80     34000\n","\n","\n","======================\n","Validation F1 (class 1) summary\n","======================\n","XGBoost_unweighted: F1(class1) = 0.5134, threshold = 0.2500\n","XGBoost_weighted: F1(class1) = 0.5087, threshold = 0.5900\n","XGBoost_weighted_calibrated: F1(class1) = 0.4882, threshold = 0.2500\n","BalancedRandomForest: F1(class1) = 0.5124, threshold = 0.6100\n","LightGBM_balanced: F1(class1) = 0.5169, threshold = 0.6300\n","LogisticRegression: F1(class1) = 0.5138, threshold = 0.2400\n","\n","BEST MODEL: LightGBM_balanced\n","Using threshold: 0.6300\n"]}],"source":["\n","results = []\n","\n","# XGBoost (unweighted)\n","xgb_unweighted = Pipeline(steps=[\n","    (\"preprocess\", preprocessor),\n","    (\"clf\", xgb.XGBClassifier(\n","        random_state=RANDOM_STATE,\n","        tree_method=\"hist\",\n","        objective=\"binary:logistic\",\n","        eval_metric=\"logloss\",\n","        n_estimators=400,\n","        learning_rate=0.07,\n","        max_depth=7,\n","        subsample=0.9,\n","        colsample_bytree=0.8,\n","        n_jobs=-1\n","    ))\n","])\n","\n","res_xgb_unweighted = evaluate_model(\"XGBoost_unweighted\", xgb_unweighted, X_train, y_train, X_val, y_val)\n","results.append(res_xgb_unweighted)\n","\n","# XGBoost (with scale_pos_weight)\n","pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n","print(f\"\\nscale_pos_weight (train) = {pos_weight:.4f}\")\n","\n","xgb_weighted = Pipeline(steps=[\n","    (\"preprocess\", preprocessor),\n","    (\"clf\", xgb.XGBClassifier(\n","        random_state=RANDOM_STATE,\n","        tree_method=\"hist\",\n","        objective=\"binary:logistic\",\n","        eval_metric=\"logloss\",\n","        n_estimators=516,\n","        learning_rate=0.07,\n","        max_depth=7,\n","        min_child_weight=2,\n","        subsample=0.8821102743060054,\n","        colsample_bytree=0.7814047095321688,\n","        scale_pos_weight=pos_weight,\n","        n_jobs=-1\n","    ))\n","])\n","\n","res_xgb_weighted = evaluate_model(\"XGBoost_weighted\", xgb_weighted, X_train, y_train, X_val, y_val)\n","results.append(res_xgb_weighted)\n","\n","# XGBoost (weighted + Calibrated)\n","CALIBRATION_SUBSAMPLE = min(40000, len(X_train))\n","idx_sub = np.random.choice(len(X_train), size=CALIBRATION_SUBSAMPLE, replace=False)\n","\n","X_cal = X_train.iloc[idx_sub]\n","y_cal = y_train.iloc[idx_sub]\n","\n","xgb_weighted_for_cal = Pipeline(steps=[\n","    (\"preprocess\", preprocessor),\n","    (\"clf\", xgb.XGBClassifier(\n","        random_state=RANDOM_STATE,\n","        tree_method=\"hist\",\n","        objective=\"binary:logistic\",\n","        eval_metric=\"logloss\",\n","        n_estimators=516,\n","        learning_rate=0.07,\n","        max_depth=7,\n","        min_child_weight=2,\n","        subsample=0.8821102743060054,\n","        colsample_bytree=0.7814047095321688,\n","        scale_pos_weight=pos_weight,\n","        n_jobs=-1\n","    ))\n","])\n","\n","calib_xgb = CalibratedClassifierCV(xgb_weighted_for_cal, method=\"sigmoid\", cv=3)\n","res_xgb_calibrated = evaluate_model(\"XGBoost_weighted_calibrated\", calib_xgb, X_cal, y_cal, X_val, y_val)\n","results.append(res_xgb_calibrated)\n","\n","# Balanced Random Forest\n","brf = Pipeline(steps=[\n","    (\"preprocess\", preprocessor),\n","    (\"clf\", BalancedRandomForestClassifier(\n","        n_estimators=400,\n","        max_depth=12,\n","        random_state=RANDOM_STATE,\n","        n_jobs=-1\n","    ))\n","])\n","\n","res_brf = evaluate_model(\"BalancedRandomForest\", brf, X_train, y_train, X_val, y_val)\n","results.append(res_brf)\n","\n","# LightGBM\n","lgbm = Pipeline(steps=[\n","    (\"preprocess\", preprocessor),\n","    (\"clf\", lgb.LGBMClassifier(\n","        n_estimators=500,\n","        learning_rate=0.03,\n","        num_leaves=50,\n","        max_depth=-1,\n","        objective=\"binary\",\n","        class_weight=\"balanced\",\n","        subsample=0.9,\n","        colsample_bytree=0.8,\n","        random_state=RANDOM_STATE,\n","        n_jobs=-1\n","    ))\n","])\n","\n","res_lgbm = evaluate_model(\"LightGBM_balanced\", lgbm, X_train, y_train, X_val, y_val)\n","results.append(res_lgbm)\n","\n","# Logistic Regression (baseline)\n","numeric_scaler = Pipeline(steps=[\n","    (\"imputer\", SimpleImputer(strategy=\"median\")),\n","    (\"scaler\", StandardScaler())\n","])\n","\n","preprocessor_lr = ColumnTransformer(\n","    transformers=[\n","        (\"num\", numeric_scaler, numeric_features),\n","        (\"cat\", categorical_transformer, categorical_features)\n","    ]\n",")\n","\n","lr = Pipeline(steps=[\n","    (\"preprocess\", preprocessor_lr),\n","    (\"clf\", LogisticRegression(\n","        C=0.008111941985431923,\n","        max_iter=1000,\n","        solver=\"liblinear\"\n","    ))\n","])\n","\n","res_lr = evaluate_model(\"LogisticRegression\", lr, X_train, y_train, X_val, y_val)\n","results.append(res_lr)\n","\n","# Summary of models\n","print(\"\\n======================\")\n","print(\"Validation F1 (class 1) summary\")\n","print(\"======================\")\n","for r in results:\n","    print(f\"{r['name']}: F1(class1) = {r['f1_class1']:.4f}, threshold = {r['threshold']:.4f}\")\n","\n","# Pick best model based on F1\n","best_result = max(results, key=lambda r: r[\"f1_class1\"])\n","best_name = best_result[\"name\"]\n","best_threshold = best_result[\"threshold\"]\n","\n","print(f\"\\nBEST MODEL: {best_name}\")\n","print(f\"Using threshold: {best_threshold:.4f}\")\n"]},{"cell_type":"code","execution_count":10,"id":"46a68809","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469},"id":"46a68809","executionInfo":{"status":"ok","timestamp":1765203297271,"user_tz":-660,"elapsed":14572,"user":{"displayName":"Julio Lim","userId":"08767434591465252695"}},"outputId":"ca4790f9-82c1-4de2-c7c5-1e2e4a7210e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Fitting BEST model on FULL training data: LightGBM_balanced\n","[LightGBM] [Info] Number of positive: 30116, number of negative: 139884\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047950 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 489\n","[LightGBM] [Info] Number of data points in the train set: 170000, number of used features: 40\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Saved submission file to: submission.csv\n"]},{"output_type":"execute_result","data":{"text/plain":["       ID  Diabetes_binary\n","0  182992                1\n","1  148963                0\n","2   82811                1\n","3  110563                1\n","4  208808                0"],"text/html":["\n","  <div id=\"df-fbab8e5a-4dbe-471e-ae1a-66a211ba7f34\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Diabetes_binary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>182992</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>148963</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>82811</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>110563</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>208808</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbab8e5a-4dbe-471e-ae1a-66a211ba7f34')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fbab8e5a-4dbe-471e-ae1a-66a211ba7f34 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fbab8e5a-4dbe-471e-ae1a-66a211ba7f34');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-749d85e6-a228-4b5b-ae96-186d4739b6ce\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-749d85e6-a228-4b5b-ae96-186d4739b6ce')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-749d85e6-a228-4b5b-ae96-186d4739b6ce button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"submission","summary":"{\n  \"name\": \"submission\",\n  \"rows\": 30000,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57898,\n        \"min\": 20004,\n        \"max\": 219999,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          190333,\n          155121,\n          42294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diabetes_binary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}],"source":["\n","# Submission\n","def build_model_by_name(name: str):\n","    if name == \"XGBoost_unweighted\":\n","        return Pipeline(steps=[\n","            (\"preprocess\", preprocessor),\n","            (\"clf\", xgb.XGBClassifier(\n","                random_state=RANDOM_STATE,\n","                tree_method=\"hist\",\n","                objective=\"binary:logistic\",\n","                eval_metric=\"logloss\",\n","                n_estimators=400,\n","                learning_rate=0.07,\n","                max_depth=7,\n","                subsample=0.9,\n","                colsample_bytree=0.8,\n","                n_jobs=-1\n","            ))\n","        ])\n","    if name == \"XGBoost_weighted\":\n","        return Pipeline(steps=[\n","            (\"preprocess\", preprocessor),\n","            (\"clf\", xgb.XGBClassifier(\n","                random_state=RANDOM_STATE,\n","                tree_method=\"hist\",\n","                objective=\"binary:logistic\",\n","                eval_metric=\"logloss\",\n","                n_estimators=516,\n","                learning_rate=0.07,\n","                max_depth=7,\n","                min_child_weight=2,\n","                subsample=0.8821102743060054,\n","                colsample_bytree=0.7814047095321688,\n","                scale_pos_weight=pos_weight,\n","                n_jobs=-1\n","            ))\n","        ])\n","    if name == \"XGBoost_weighted_calibrated\":\n","        base = Pipeline(steps=[\n","            (\"preprocess\", preprocessor),\n","            (\"clf\", xgb.XGBClassifier(\n","                random_state=RANDOM_STATE,\n","                tree_method=\"hist\",\n","                objective=\"binary:logistic\",\n","                eval_metric=\"logloss\",\n","                n_estimators=516,\n","                learning_rate=0.07,\n","                max_depth=7,\n","                min_child_weight=2,\n","                subsample=0.8821102743060054,\n","                colsample_bytree=0.7814047095321688,\n","                scale_pos_weight=pos_weight,\n","                n_jobs=-1\n","            ))\n","        ])\n","        return CalibratedClassifierCV(base, method=\"sigmoid\", cv=3)\n","\n","    if name == \"BalancedRandomForest\":\n","        return Pipeline(steps=[\n","            (\"preprocess\", preprocessor),\n","            (\"clf\", BalancedRandomForestClassifier(\n","                n_estimators=400,\n","                max_depth=12,\n","                random_state=RANDOM_STATE,\n","                n_jobs=-1\n","            ))\n","        ])\n","\n","    if name == \"LightGBM_balanced\":\n","        return Pipeline(steps=[\n","            (\"preprocess\", preprocessor),\n","            (\"clf\", lgb.LGBMClassifier(\n","                n_estimators=500,\n","                learning_rate=0.03,\n","                num_leaves=50,\n","                max_depth=-1,\n","                objective=\"binary\",\n","                class_weight=\"balanced\",\n","                subsample=0.9,\n","                colsample_bytree=0.8,\n","                random_state=RANDOM_STATE,\n","                n_jobs=-1\n","            ))\n","        ])\n","\n","    if name == \"LogisticRegression\":\n","        return Pipeline(steps=[\n","            (\"preprocess\", preprocessor_lr),\n","            (\"clf\", LogisticRegression(\n","                C=0.008111941985431923,\n","                max_iter=1000,\n","                solver=\"liblinear\"\n","            ))\n","        ])\n","\n","    raise ValueError(f\"Unknown model name: {name}\")\n","\n","final_model = build_model_by_name(best_name)\n","\n","print(f\"\\nFitting BEST model on FULL training data: {best_name}\")\n","final_model.fit(X, y)\n","\n","# Predict probabilities on test set\n","test_proba = final_model.predict_proba(X_test)[:, 1]\n","test_pred = (test_proba >= best_threshold).astype(int)\n","\n","submission = pd.DataFrame({\n","    ID_COL: test_ids,\n","    TARGET_COL: test_pred\n","})\n","\n","submission_path = \"submission.csv\"\n","submission.to_csv(submission_path, index=False)\n","print(f\"\\nSaved submission file to: {submission_path}\")\n","submission.head()\n"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}